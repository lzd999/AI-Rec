# 基于协同过滤的召回

协同过滤（Collaborative Filtering）推荐算法是最经典、最常用的推荐算法。

核心思想是根据当前用户的历史喜好和与当前用户有相似兴趣的其它用户向当前用户推荐物品。

目前应用比较广泛的协同过滤算法分为：

1.基于**用户**的协同过滤算法（**UserCF**）：向当前用户推荐和他兴趣相似的其它用户喜欢的物品

2.基于**物品**的协同过滤算法（**ItemCF**）：给用户推荐和他之前喜欢的物品相似的物品。

## 相似性度量方法

1.**杰卡德（Jaccard）相似系数**

`Jaccard` 系数是衡量两个集合的相似度一种指标，计算公式如下：
$$
sim_{uv}=\frac{|N(u) \cap N(v)|}{|N(u)| \cup|N(v)|}
$$

+ 其中 $N(u)$，$N(v)$ 分别表示用户 $u$ 和用户 $v$ 交互物品的集合。

+ 对于用户 $u$ 和 $v$ ，该公式反映了两个交互物品交集的数量占这两个用户交互物品并集的数量的比例。

由于杰卡德相似系数一般无法反映具体用户的评分喜好信息，所以常用来评估用户是否会对某物品进行打分， 而不是预估用户会对某物品打多少分。

2.**余弦相似度**
余弦相似度衡量了两个向量的夹角，夹角越小越相似。余弦相似度的计算如下，其与杰卡德（Jaccard）相似系数只是在分母上存在差异：
$$
sim_{uv}=\frac{|N(u) \cap N(v)|}{\sqrt{|N(u)|\cdot|N(v)|}}
$$
从向量的角度进行描述，令矩阵 $A$ 为用户-物品交互矩阵，矩阵的行表示用户，列表示物品。

+ 设用户和物品数量分别为 $m,n$，交互矩阵$A$就是一个 $m$ 行 $n$ 列的矩阵。

+ 矩阵中的元素均为 $0/1$。若用户 $i$ 对物品 $j$ 存在交互，那么 $A_{i,j}=1$，否则为 $0$ 。

+ 那么，用户之间的相似度可以表示为：
  $$
  sim_{uv} = cos(u,v) =\frac{u\cdot v}{|u|\cdot |v|}
  $$

    + 向量 $u,v$ 在形式都是 one-hot 类型，$u\cdot v$ 表示向量点积。

上述用户-物品交互矩阵在现实中是十分稀疏的，为了节省内存，交互矩阵会采用字典进行存储。

3.**皮尔逊相关系数**

在用户之间的余弦相似度计算时，将用户向量的内积展开为各元素乘积和：
$$
sim_{uv} = \frac{\sum_i r_{ui}*r_{vi}}{\sqrt{\sum_i r_{ui}^2}\sqrt{\sum_i r_{vi}^2}}
$$

+ 其中，$r_{ui},r_{vi}$ 分别表示用户 $u$ 和用户 $v$ 对物品 $i$ 是否有交互(或具体评分值)。

皮尔逊相关系数与余弦相似度的计算公式非常的类似，如下：
$$
sim(u,v)=\frac{\sum_{i\in I}(r_{ui}-\bar r_u)(r_{vi}-\bar r_v)}{\sqrt{\sum_{i\in I }(r_{ui}-\bar r_u)^2}\sqrt{\sum_{i\in
I }(r_{vi}-\bar r_v)^2}}
$$

+ 其中，$r_{ui},r_{vi}$ 分别表示用户 $u$ 和用户 $v$ 对物品 $i$ 是否有交互(或具体评分值)；
+ $\bar r_u, \bar r_v$ 分别表示用户 $u$ 和用户 $v$ 交互的所有物品交互数量或者评分的平均值；

相较于余弦相似度，皮尔逊相关系数通过使用用户的平均分对各独立评分进行修正，减小了用户评分偏置的影响。

## UserCF

**1.核心思想**

通过找到与当前用户兴趣爱好相似的其它用户，将其它用户喜欢的物品推荐给当前用户

**2.计算过程**

a.根据已有用户对每个物品的打分情况，将其抽象成向量，计算当前用户与已有用户在共同物品上的相似度，对相似度排序，得到 Top-N
个相似用户

b.根据 Top-N 个用户对被推荐物品的评分和他们与当前用户的相似度，计算当前用户对待推荐物品的可能评分。如果评分高则推荐给当前用户，否则不推荐

**3.不足**

a.数据稀疏性

大型推荐系统可能会出现用户间购买物品的重叠性较低，导致 UserCF 无法找到与当前用户偏好相似的其他用户

b.算法扩展性

UserCF 需要不断维护用户相似度矩阵，该矩阵占用的存储空间会随着用户数量的增加而增加，因此不适用于用户数据量比较大的场景

**4.适用场景**

**用户少， 物品多， 时效性较强**。例如新闻推荐场景， 因为新闻本身兴趣点分散，
相比用户对不同新闻的兴趣偏好，闻的及时性，热点性往往更加重要，所以正好适用于发现热点，跟踪热点的趋势。还有具有推荐新信息的能力，更有可能发现惊喜，因为看的是人与人的相似性，推出来的结果可能更有惊喜，可以发现用户潜在但自己尚未察觉的兴趣爱好。

## **ItemCF**

**1.核心思想**

预先根据所有用户的历史行为数据，计算物品间的相似性，再向当前用户推荐与他之前喜欢的物品相似的物品。

**2.计算过程**

a.将每个物品的评分抽象成向量，计算每个物品与其他物品的相似度，结合当前用户的历史喜欢物品，对相似度排序，得到 Top-N 个相似物品

b.根据当前用户对这 Top-N 个物品的评分去预测当前用户对待推荐物品的可能评分，如果评分高则推荐给当前用户，否则不推荐。

**3.不足**

a.算法扩展性

ItemCF 需要不断维护物品相似度矩阵，不适用于物品数据量比较大的场景

**4.适用场景**

**物品少，用户多，用户兴趣固定持久， 物品更新速度不是太快**。例如推荐艺术品， 音乐， 电影。

## 算法评估

对用户 $u$ 推荐 $N$ 个物品记为 $R(u)$, 令用户 $u$ 在测试集上喜欢的物品集合为$T(u)$

### 召回率

召回率定义为：
$$
\operatorname{Recall}=\frac{\sum_{u}|R(u) \cap T(u)|}{\sum_{u}|T(u)|}
$$

+ 含义：在召回模型预测的物品中，预测准确的物品占用户实际喜欢的物品的比例。

### 精确率

精确率定义为：
$$
\operatorname{Precision}=\frac{\sum_{u} \mid R(u) \cap T(u)|}{\sum_{u}|R(u)|}
$$

+ 含义：推荐的物品中，对用户准确推荐的物品占总物品的比例。

可以看出，在推荐系统中，想要召回率高则是推荐更多的物品，只要推荐越多那么就一定会涵盖用户喜欢的物品；然而推荐的物品往往在用户喜欢的物品只占少数，导致精确率较低；因此实际应用时需要权衡召回率和精确率。

### 覆盖率

覆盖率反映了推荐算法发掘长尾的能力， 覆盖率越高， 说明推荐算法越能将长尾中的物品推荐给用户。
$$
\text { Coverage }=\frac{\left|\bigcup_{u \in U} R(u)\right|}{|I|}
$$

含义：推荐系统能够推荐出来的物品占总物品集合的比例。

+ 其中 $|I|$ 表示所有物品的个数；
+ 系统的用户集合为$U$;
+ 推荐系统给每个用户推荐一个长度为 $N$ 的物品列表$R(u)$.

覆盖率表示最终的推荐列表中包含多大比例的物品。如果所有物品都被给推荐给至少一个用户， 那么覆盖率是100%。

### 新颖度

一般用推荐列表中物品的平均流行度衡量推荐结果的新颖度。 如果推荐出的物品都很热门， 说明推荐的新颖度较低。由于物品的流行度分布呈长尾分布，
所以为了使得流行度的平均值更加稳定， 在计算平均流行度时会对每个物品的流行度取对数。

## 权重改进

基础公式：
$$
w_{i j}=\frac{|N(i) \bigcap N(j)|}{|N(i)|}
$$

​ 该公式表示同时喜欢物品 $i$ 和物品 $j$ 的用户数，占喜欢物品 $i$ 用户数的比例。然而如果物品 $j$ 为热门物品，那么它与任何物品的相似度都很高。

1.对热门物品进行惩罚
$$
w_{i j}=\frac{|N(i) \cap N(j)|}{\sqrt{|N(i)||N(j)|}}
$$
在基础公式的分母再除以一个物品 $j$ 被购买的数量，此时如果物品 $j$ 为热门物品，则 $N(j)$ 会很高，使得整体变小

2.控制对热门物品的惩罚力度
$$
w_{i j}=\frac{|N(i) \cap N(j)|}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
$$

可以在 1. 的基础上再增加权重 $α$ ，通过控制 $α$ 从而控制对热门物品的惩罚力度。

3.增加对活跃用户的惩罚
$$
w_{i j}=\frac{\sum_{\operatorname{\text {u}\in N(i) \cap N(j)}} \frac{1}{\log 1+|N(u)|}}{|N(i)|^{1-\alpha}|N(j)
|^{\alpha}}
$$
1 和 2 仅考虑了对热门物品的惩罚，但未考虑到对活跃用户的惩罚，对异常活跃的用户，在计算物品之间的相似度时，其贡献应该小于非活跃用户。

## 算法分析与局限性

无论是 UserCF 还是
ItemCF，可以看出协同过滤算法仅关注物品与物品之间，无法将两个物品的相似信息推广到其它物品间的相似性上，导致推荐系统长时间运行后会使得热门物品具备很强的头部效应，即会跟大量物品产生相似度，而冷门物品由于特征向量稀疏，导致极少被推荐。即
**头部效应明显， 处理稀疏向量的能力弱**。

# 改进

## 改进一：Swing 算法

### 应用场景

在大规模的电商推荐系统中，需要实时对用户各类行为做出海量预测，为了保证这种实时性，其严重依赖于提前计算好的产品索引，即给定种子产品，返回排序后的候选相关产品列表。相关性产品索引主要分为两种：替代性产品和互补性产品。

例如不同风格的衬衫构成了替代关系，生成的产品索引属于替代性产品索引；衬衫与风衣、裤子等形成的搭配构成了互补关系，生成的产品索引属于互补性产品索引。用户在购买某种衬衫前，希望看到多种不同风格的衬衫；在购买某种衬衫后，希望看到与这衬衫搭配的风衣、裤子等而非继续看其它种类衬衫。

### 改进贡献

Swing 算法改进了 ItemCF 存在的缺陷：

ItemCF
关注了物品与物品间的相似度，基于之前喜欢某个物品的用户一定会喜欢推荐的同种物品的假设，但未考虑推荐的用户集合内部用户与用户之间的相似度可能会比较高。例如推荐系统向某个微信群的用户推送了XX网站护肤品打折和XX公司裁员的笔记，显然这两篇笔记必然不相关，但由于微信群内的用户都点击、浏览了这两篇笔记，根据
ItemCF 的算法来看会让推荐系统认为这两篇笔记相似度非常高，会导致推荐系统产生错误判断。

Swing 算法为用户设置权重，解决 ItemCF 可能出现的 “小圈子” 问题

### 具体内容

**1.核心思想**

若用户 $u$ 和用户 $v$ 之间除了购买过物品 $i$ 外，还购买过物品 $j$
，则认为两件物品在某种程度上是相似的。也就是说，商品与商品之间的相似关系，是通过用户间的关系来传递的。在计算物品 $i$ 和 $j$
的相似度时，同时计算购买了物品 $i$ 和 $j$ 的用户 $u$ 和用户 $v$ 的相似度，如果这两个用户共同购买的物品越少，可以说明这两个用户的历史兴趣不相似，但仍然购买了物品
$i$ 和 $j$，则才能说明物品 $i$ 和 $j$ 的相似性越高。

**2.计算过程**

Swing 算法的计算公式如下：

$$s(i,j)=\sum\limits_{u\in U_i\cap U_j} \sum\limits_{v \in U_i\cap U_j}w_u*w_v* \frac{1}{\alpha+|I_u \cap I_v|}$$

其中 $U_i$ 是点击过商品 $i$ 的用户集合，$I_u$ 是用户 $u$ 点击过的商品集合，加入参数 $\alpha$ 防止分母为 0。

$w_u=\frac{1}{\sqrt{|I_u|}},w_v=\frac{1}{\sqrt{|I_v|}}$ 表示用户的权重参数，以降低 “小圈子” 用户的影响。

**3.编程实现**

```python
from collections import defaultdict
from itertools import combinations

import pandas as pd


def load_data(root_path):
    column_names = ['user_id', 'movie_id', 'rating']
    train_data = pd.read_csv(root_path, sep=', ', engine='python', names=column_names)
    return train_data


def get_user_items_user(train_data):
    user_items = defaultdict(set)
    items_user = defaultdict(set)
    for i, row in train_data.iterrows():
        user_items[row['user_id']].add(row['movie_id'])
        items_user[row['movie_id']].add(row['user_id'])
    return user_items, items_user


def Swing_Rec(user_items, items_user, alpha):
    items_pairs = list(combinations(items_user.keys(), 2))  # 生成 (物品, 物品) 的全排列对
    items_dict = defaultdict(dict)
    for (i, j) in items_pairs:
        # 与物品 i 存在交互的用户和与物品 j 存在交互的用户取交集后生成 (用户, 用户) 的全排列对
        user_pairs = list(combinations(items_user[i] & items_user[j], 2))
        res = 0
        for (u, v) in user_pairs:
            res += 1 / (alpha + len(list(user_items[u] & user_items[v])))  # Swing 算法公式
        if res != 0:
            items_dict[i][j] = format(res, '.6f')
    return items_dict


if __name__ == "__main__":
    train_data_path = "../data/record.txt"
    train_data = load_data(train_data_path)
    user_items, items_user = get_user_items_user(train_data)
    alpha = 1.0
    rec_items = Swing_Rec(user_items, items_user, alpha)
    for k, v in rec_items.items():
        print("k:{}, v:{}".format(k, v))
```

### Surprise算法

首先在行为相关性中引入连续时间衰减因子，然后引入基于交互数据的聚类方法解决数据稀疏的问题，旨在帮助用户找到互补商品。互补相关性主要从三个层面考虑，
**类别**层面，**商品**层面和**聚类**层面。

- 类别层面
  首先通过商品和类别的映射关系，我们可以得到 user-category 矩阵。随后使用简单的相关性度量可以计算出类别 $i,j$ 的相关性。

  $\theta_{i,j}=p(c_{i,j}|c_j)=\frac{N(c_{i,j})}{N(c_j)}$

  即，$N(c_{i,j})$ 为在购买过i之后购买j类的数量，$N(c_{j})$ 为购买j类的数量。

  由于类别直接的种类差异，每个类别的相关类数量存在差异，因此采用最大相对落点来作为划分阈值。

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片max_drop.png" alt="在这里插入图片描述" style="zoom:30%;" /> 
  </div>

例如图(a)中T恤的相关类选择前八个，图(b)中手机的相关类选择前三个。

- 商品层面
  商品层面的相关性挖掘主要有两个关键设计：

    - 商品的购买顺序是需要被考虑的，例如在用户购买手机后推荐充电宝是合理的，但在用户购买充电宝后推荐手机是不合理的。
    - 两个商品购买的时间间隔也是需要被考虑的，时间间隔越短越能证明两个商品的互补关系。

  最终商品层面的互补相关性被定义为：

  $s_{1}(i, j)=\frac{\sum_{u \in U_{i} \cap U_{j}} 1 /\left(1+\left|t_{u i}-t_{u j}\right|\right)}{\left\|U_{i}\right\|
  \times\left\|U_{j}\right\|}$,其中 $j$ 属于 $i$ 的相关类，且 $j$ 的购买时间晚于 $i$。

- 聚类层面

    - 如何聚类？
      传统的聚类算法（基于密度和 k-means ）在数十亿产品规模下的淘宝场景中不可行，所以作者采用了标签传播算法。
    - 在哪里标签传播？
      Item-item 图，其中以 Swing 算法得到的排名靠前的 item 为邻居，边的权重就是 Swing 分数。
    - 表现如何？
      快速而有效，15分钟即可对数十亿个项目进行聚类。
      最终聚类层面的相关度计算同上面商品层面的计算公式

- 线性组合：
  $s(i, j)=\omega * s_{1}(i, j)+(1-\omega) * s_{2}(i, j)$

  其中 $\omega=0.8$ 是作者设置的权重超参数。

  Surprise 算法通过利用类别信息和标签传播技术解决了用户共同购买图上的稀疏性问题。

## 改进二：矩阵分解 MF

### 改进贡献

**矩阵分解**（Matrix Factorization, MF）使得协同过滤能更好地处理稀疏矩阵问题，
增强泛化能力。具体做法是通过挖掘用户和物品的隐含兴趣和隐含特征，在用户和物品协同过滤矩阵的基础上， 使用**更稠密的隐向量**
表示用户和物品，从而在一定程度上弥补协同过滤模型处理稀疏矩阵能力不足的问题。

### 隐语义模型

隐语义模型最早在文本领域被提出，用于寻找文本的隐含语义。2006年开始用于推荐系统，其核心思想是通过**隐含特征**（latent
factor）将用户兴趣和物品产生联系，基于用户的历史行为找出潜在的主题和分类， 再对物品进行自动聚类，将其划分到不同类别 /
主题（用户的兴趣）。

协同过滤算法和隐语义模型的区别是什么？

以项亮老师《推荐系统实践》书中的内容为例：

> 如果我们知道了用户A和用户B两个用户在豆瓣的读书列表， 从他们的阅读列表可以看出，用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书，
> 而用户B的兴趣比较集中在数学和机器学习方面。 那么如何给A和B推荐图书呢？ 先说说协同过滤算法， 这样好对比不同：
>
>* 对于UserCF，首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他们推荐那些用户喜欢的其他书。
>* 对于ItemCF，需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。
>
>而如果是隐语义模型的话， 它会先通过一些角度把用户兴趣和这些书归一下类， 当来了用户之后， 首先得到他的兴趣分类，
> 然后从这个分类中挑选他可能喜欢的书籍。

可以看出，协同过滤算法与隐语义模型的区别在于隐语义模型利用了物品的**隐含特征**，例如对于书籍，其内容， 作者， 年份，
主题等都可以算隐含特征。

### 实例：用户对音乐评分

假设每个用户都有自己的听歌偏好，例如用户 A 倾向于听王菲演唱、使用吉他伴奏、小清新风格的歌曲，那么就可以为他推荐同样是王菲演唱、使用吉他伴奏、小清新风格的其它歌曲，也就是
**王菲**、**吉他伴奏**、**小清新**这 3 个标签在用户和歌曲之间建立了连接。

每个用户的听歌偏好必然不相同，每首歌包含的元素也肯定不相同，但推荐系统希望找到这样两种矩阵：

1.用户矩阵P —— 潜在因子

用户矩阵 P 表示了不同用户对不同元素的偏好程度， 1代表很喜欢，0代表不喜欢，例如：

<img src="C:\Users\李泽栋\Pictures\Saved Pictures\推荐系统笔记\用户矩阵Q.jpg" alt="用户矩阵Q" style="zoom:50%;" />

2.音乐矩阵 Q ——潜在因子

音乐矩阵 Q 表示了不同音乐包含对应元素的轻重成分，例如：

<img src="C:\Users\李泽栋\Pictures\Saved Pictures\推荐系统笔记\音乐矩阵P.jpg" alt="音乐矩阵P" style="zoom:50%;" />

假设现在推荐系统需要计算张三对音乐 A 的评分，那么可以将张三和音乐 A 在这 5
个分类上组成的向量进行内积，即张三对小清新的偏好 * 音乐 A 包含小清新的成分 + 张三对重口味的偏好 * 音乐 A
包含重口味的成分......即$$0.6 * 0.9 + 0.8 * 0.1 + 0.1 * 0.2 + 0.1 * 0.4 + 0.7 * 0 = 0.68$$，最终推荐系统使用隐语义模型计算出张三对音乐
A 的评分可能为 $0.68$。

<img src="C:\Users\李泽栋\Pictures\Saved Pictures\推荐系统笔记\张三与音乐A.jpg" alt="张三与音乐A" style="zoom:50%;" />

最终推荐系统使用隐语义模型计算得到的所有用户对音乐的评分矩阵如下：

（红色表示用户未打分，通过隐向量计算得到的）

<img src="C:\Users\李泽栋\Pictures\Saved Pictures\推荐系统笔记\评分矩阵.jpg" alt="评分矩阵" style="zoom:50%;" />

### 总结

1.实例的小清新、重口味、优雅等可以看做是隐含特征，在实际应用场景中，隐含特征可能是具体的，可能是抽象的，为用户兴趣和物品风格建立联系，将相似的物品推荐给相似的用户。

2.隐语义模型的本质是通过**隐向量**将用户相似矩阵和物品相似矩阵做**相同数量不同维度**的分解，得到了**用户—潜在因子矩阵
P **和**物品—潜在因子矩阵 Q **，这是对协同过滤算法的一种**延伸**。

3.但实际应用场景中，通常只有用户—物品的评分矩阵：

<img src="C:\Users\李泽栋\Pictures\Saved Pictures\推荐系统笔记\用户—物品评分矩阵.jpg" alt="用户—物品评分矩阵" style="zoom:50%;" />

可以看出，这个矩阵非常稀疏，UserCF 或者 ItemCF 都难以填充未知部分，并且容易出现长尾问题；而如果使用隐语义模型，就需要将该矩阵分解为用户—潜在因子矩阵
P 和物品潜在因子矩阵 Q，可轻松解决。

### 矩阵分解

#### 算法原理

矩阵分解算法是**通过分解协同过滤的评分矩阵来得到用户和物品的隐向量**，例如：

<img src="C:\Users\李泽栋\Pictures\Saved Pictures\推荐系统笔记\矩阵分解原理.jpg" alt="矩阵分解原理" style="zoom:70%;" />

1.将 $m\times n$ 维的评分矩阵 $R$ ，分解成 $m \times k$ 维的用户矩阵 $U$ 和 $k \times n$ 维的物品矩阵 $V$ 相乘的形式。其中
$m$ 表示用户数量， $n$ 表示物品数量， $k$ 表示隐向量维度，即隐含特征的个数。

2.隐含特征可具体可抽象，大多场景不具备可解释性，需要模型自行学习。

3.一般而言，隐向量维度 $k$
越大，则隐向量能承载的信息内容越多，表达能力也会更强，但相对应的学习难度也会增加。所以，我们需要根据训练集样本的数量去选择合适的隐向量维度大小，能保证信息学习相对完整的前提下，降低模型的学习难度。

#### 评分预测

在矩阵分解得到用户矩阵和物品矩阵后，若要计算用户 $u$ 对物品 $i$ 的评分，公式如下：
$$
\operatorname{Preference}(u, i)=r_{u i}=p_{u}^{T} q_{i}=\sum_{k=1}^{K} p_{u, k} q_{i,k}
$$

+ 其中，向量 $p_u$ 表示用户 $u$ 的隐向量，向量 $q_i$ 表示物品 $i$ 的隐向量。
+ 用户向量和物品向量的内积 $p_{u}^{T} q_{i}$ 可以表示为用户 $u$ 对物品 $i$ 的预测评分。
+ $p_{u,k}$ 和 $q_{i,k}$ 是模型的参数， $p_{u,k}$ 度量的是用户 $u$ 的兴趣和第 $k$ 个隐类的关系，$q_{i,k}$ 度量了第 $k$
  个隐类和物品 $i$ 之间的关系。

#### 求解

经典的矩阵分解方法有**特征值分解（EVD）**和**奇异值分解（SVD）**：

1.特征值分解 EVD 要求分解的矩阵是**方阵**，而目前绝大部分应用场景的用户—物品矩阵不满足这个要求。

2.奇异值分解 SVD 要求原始矩阵是**稠密**的，而目前绝大部分应用场景的用户—物品评分矩阵是非常稀疏的。

​ a.如果想用奇异值分解， 就必须对**缺失元素**进行**预处理**（比如填 0 ）。

​ b.填充不但会导致空间复杂度增高，且补全内容不一定准确。

​ c.SVD 分解计算复杂度非常高，而用户-物品的评分矩阵较大，不具备普适性。

### FunkSVD

2006年的Netflix Prize之后， Simon Funk公布了一个矩阵分解算法叫做**Funk-SVD**, 后来被 Netflix Prize 的冠军Koren称为*
*Latent Factor Model(LFM)**。

Funk-SVD的思想很简单： **把求解上面两个矩阵的参数问题转换成一个最优化问题， 可以通过训练集里面的观察值利用最小化来学习用户矩阵和物品矩阵
**。

**算法过程**

1. 根据前面提到的，在有用户矩阵和物品矩阵的前提下，若要计算用户 $u$ 对物品 $i$ 的评分， 可以根据公式：
   $$
   \operatorname{Preference}(u, i)=r_{u i}=p_{u}^{T} q_{i}=\sum_{k=1}^{K} p_{u, k} q_{i,k}
   $$

    + 其中，向量 $p_u$ 表示用户 $u$ 的隐向量，向量 $q_i$ 表示物品 $i$ 的隐向量。

2. 随机初始化一个用户矩阵 $U$ 和一个物品矩阵 $V$，获取每个用户和物品的初始隐语义向量。

3. 将用户和物品的向量内积 $p_{u}^{T} q_{i}$， 作为用户对物品的预测评分 $\hat{r}_{u i}$。

    + $\hat{r}_{u i}=p_{u}^{T} q_{i}$ 表示的是通过建模，求得的用户 $u$ 对物品的预测评分。
    + 在用户对物品的评分矩阵中，矩阵中的元素 $r_{u i}$ 才是用户对物品的真实评分。

4. 对于评分矩阵中的每个元素，计算预测误差 $e_{u i}=r_{u i}-\hat{r}_{u i}$，对所有训练样本的平方误差进行累加：
   $$
   \operatorname{SSE}=\sum_{u, i} e_{u i}^{2}=\sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)^{2}
   $$

    + 从上述公式可以看出，$SSE$ 建立起了训练数据和预测模型之间的关系。

    + 如果我们希望模型预测的越准确，那么在训练集（已有的评分矩阵）上的预测误差应该仅可能小。

    + 为方便后续求解，给 $SSE$ 增加系数 $1/2$ ：
      $$
      \operatorname{SSE}=\frac{1}{2} \sum_{u, i} e_{u i}^{2}=\frac{1}{2} \sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u k}
      q_{i k}\right)^{2}
      $$

5. 前面提到，模型预测越准确等价于预测误差越小，那么优化的目标函数变为：
   $$
   \min _{\boldsymbol{q}^{*}, \boldsymbol{p}^{*}} \frac{1}{2} \sum_{(u, i) \in K}\left(\boldsymbol{r}_{\mathrm{ui}}-p_
   {u}^{T} q_{i}\right)^{2}
   $$

    + $K$ 表示所有用户评分样本的集合，**即评分矩阵中不为空的元素**，其他空缺值在测试时是要预测的。
    + 该目标函数需要优化的目标是用户矩阵 $U$ 和一个物品矩阵 $V$。

6. 对于给定的目标函数，可以通过**梯度下降法**对参数进行优化。

    + 求解目标函数 $SSE$ 关于用户矩阵中参数 $p_{u,k}$ 的梯度：
      $$
      \frac{\partial}{\partial p_{u,k}} S S E=\frac{\partial}{\partial p_{u,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u
      i} \frac{\partial}{\partial p_{u,k}} e_{u i}=e_{u i} \frac{\partial}{\partial p_{u,k}}\left(r_{u i}-\sum_{k=1}^{K}
      p_{u,k} q_{i,k}\right)=-e_{u i} q_{i,k}
      $$

    + 求解目标函数 $SSE$ 关于 $q_{i,k}$ 的梯度：
      $$
      \frac{\partial}{\partial q_{i,k}} S S E=\frac{\partial}{\partial q_{i,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u
      i} \frac{\partial}{\partial q_{i,k}} e_{u i}=e_{u i} \frac{\partial}{\partial q_{i,k}}\left(r_{u i}-\sum_{k=1}^{K}
      p_{u,k} q_{i,k}\right)=-e_{u i} p_{u,k}
      $$

7. 参数梯度更新
   $$
   p_{u, k}=p_{u,k}-\eta (-e_{ui}q_{i, k})=p_{u,k}+\eta e_{ui}q_{i, k} \\
   q_{i, k}=q_{i,k}-\eta (-e_{ui}p_{u,k})=q_{i, k}+\eta e_{ui}p_{u, k}
   $$

    + 其中，$\eta$ 表示学习率，用于控制步长。
    + 然而有一个问题就是当参数很多的时候，也就是两个矩阵很大的时候，往往容易陷入过拟合的困境，这时候就需要在目标函数上面加项，对
      SVD
      进行改进（[SVD 家族及其衍生](https://blog.csdn.net/weixin_46351593/article/details/130869414?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172068702616800215033377%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172068702616800215033377&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-130869414-null-null.142^v100^pc_search_result_base6&utm_term=SVD%20RSVD&spm=1018.2226.3001.4187)）。

**加入正则项**

为了控制模型的复杂度。在原有模型的基础上，加入 $l2$ 正则项，来防止过拟合。

+ 当模型参数过大，而输入数据发生变化时，可能会造成输出的不稳定。

+ $l2$ 正则项等价于假设模型参数符合0均值的正态分布，从而使得模型的输出更加稳定。

$$
\min _{\boldsymbol{q}^{*}, \boldsymbol{p}^{*}} \frac{1}{2} \sum_{(u, i) \in K}\left(\boldsymbol{r}_{\mathrm{ui}}-p_
{u}^{T} q_{i}\right)^{2}

+ \lambda\left(\left\|p_{u}\right\|^{2}+\left\|q_{i}\right\|^{2}\right)
  $$

### BiasSVD

在推荐系统中，评分预测除了与用户的兴趣偏好、物品的特征属性相关外，与其他的因素也相关。例如：

+ 例如，对于乐观的用户来说，它的评分行为普遍偏高，而对批判性用户来说，他的评分记录普遍偏低，即使他们对同一物品的评分相同，但是他们对该物品的喜好程度却并不一样。
+ 对物品来说也是类似的。以电影为例，受大众欢迎的电影得到的评分普遍偏高，而一些烂片的评分普遍偏低，这些因素都是独立于用户或产品的因素，和用户对产品的的喜好无关。

因此， Netfix Prize中提出了另一种LFM， 在原来的基础上加了偏置项， 来消除用户和物品打分的偏差， 即预测公式如下：
$$
\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}
$$
这个预测公式加入了3项偏置参数 $\mu,b_u,b_i$, 作用如下：

- $\mu$： 该参数反映的是推荐模型整体的平均评分，一般使用所有样本评分的均值。
- $b_u$：用户偏差系数。可以使用用户 $u$ 给出的所有评分的均值， 也可以当做训练参数。
    - 这一项表示了用户的评分习惯中和物品没有关系的那种因素。 比如有些用户比较苛刻， 对什么东西要求很高， 那么他评分就会偏低，
      而有些用户比较宽容， 对什么东西都觉得不错， 那么评分就偏高
- $b_i$：物品偏差系数。可以使用物品 $i$ 收到的所有评分的均值， 也可以当做训练参数。
    - 这一项表示了物品接受的评分中和用户没有关系的因素。 比如有些物品本身质量就很高， 因此获得的评分相对比较高，
      有的物品本身质量很差， 因此获得的评分相对较低。

加了用户和物品的打分偏差之后， 矩阵分解得到的隐向量更能反映不同用户对不同物品的“真实”态度差异， 也就更容易捕捉评价数据中有价值的信息，
从而避免推荐结果有偏。

**优化函数**

在加入正则项的FunkSVD的基础上，BiasSVD 的目标函数如下：
$$
\begin{aligned}
\min _{q^{*}, p^{*}} \frac{1}{2} \sum_{(u, i) \in K} &\left(r_{u i}-\left(\mu+b_{u}+b_{i}+q_{i}^{T} p_{u}\right)\right)
^{2} \\
&+\lambda\left(\left\|p_{u}\right\|^{2}+\left\|q_{i}\right\|^{2}+b_{u}^{2}+b_{i}^{2}\right)
\end{aligned}
$$
可得偏置项的梯度更新公式如下：

+ $\frac{\partial}{\partial b_{i}} S S E=-e_{u i}+\lambda b_{i}$
+ $ \frac{\partial}{\partial b_{u}} S S E=-e_{u i}+\lambda b_{u} \ $

### 算法分析

* 优点：
    * 泛化能力强： 一定程度上解决了稀疏问题
    * 空间复杂度低： 由于用户和物品都用隐向量的形式存放， 少了用户和物品相似度矩阵， 空间复杂度由$n^2$降到了$(n+m)*f$
    * 更好的扩展性和灵活性：矩阵分解的最终产物是用户和物品隐向量， 这和深度学习的 embedding 思想不谋而合，
      因此矩阵分解的结果非常便于与其他特征进行组合和拼接， 并可以与深度学习无缝结合。

+ 缺点：
    + 矩阵分解算法依然是只用到了评分矩阵， 没有考虑到用户特征， 物品特征和上下文特征， 这使得矩阵分解丧失了利用很多有效信息的机会。
    + 同时在缺乏用户历史行为的时候， 无法进行有效的推荐。
    + 为了解决这个问题， **逻辑回归模型及后续的因子分解机模型**， 凭借其天然的融合不同特征的能力， 逐渐在推荐系统领域得到了更广泛的应用。 

